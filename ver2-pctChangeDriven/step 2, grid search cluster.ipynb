{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9aaa4fcc-1a03-4f20-a9dd-7ce3d60ccb52",
   "metadata": {},
   "source": [
    "## premise: Grid search for clustering solution\n",
    "\n",
    "via skleanr pipeline and grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "beea8fea-ae81-4e3f-9bff-fc4f8bd3f443",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0084e4ae-20f9-4081-93df-7822264899b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load pipeline 1 csv and prep for clustering\n",
    "m2_pipeline = pd.read_csv('pipeline1.csv')\n",
    "\n",
    "#change is surge price rate of change per observation, change.1 is precursor\n",
    "#sum_change is surge sum_change per surge, and surge_area is surge alone\n",
    "keepable = ['precursor_buy_cap_pct_change', \n",
    "            'precursor_ask_cap_pct_change',\n",
    "            'precursor_bid_vol_pct_change', \n",
    "            'precursor_ask_vol_pct_change', 'change.1',\n",
    "            'surge_targets_met_pct']\n",
    "m2_pipeline = m2_pipeline[keepable]\n",
    "m2_pipeline = m2_pipeline.dropna()\n",
    "print(m2_pipeline.isna().sum(axis=1).astype(bool).sum())\n",
    "m2_pipeline = m2_pipeline.astype('float')\n",
    "m2_pipeline.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db9b5d97-4176-40d4-812d-94a933e75878",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Perform the grid search\u001b[39;00m\n\u001b[1;32m     21\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(pipe, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m---> 22\u001b[0m grid_search\u001b[38;5;241m.\u001b[39mfit(\u001b[43mX\u001b[49m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Print the best parameters and score\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters: \u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_search\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN #cluster types\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define the pipeline\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('cluster', KMeans())\n",
    "])\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'cluster': [KMeans(), AgglomerativeClustering(), DBSCAN()],\n",
    "    'cluster__n_clusters': range(2, 11),\n",
    "    'cluster__eps': [0.1, 0.5, 1],\n",
    "    'cluster__min_samples': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Perform the grid search\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=5)\n",
    "grid_search.fit(X)\n",
    "\n",
    "# Print the best parameters and score\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cb63804-9dce-46a7-b957-48183ed5af2d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SpectralClustering\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Assuming 'df' is a pandas dataframe\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Replace 'affinity' with the appropriate affinity matrix\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Replace 'n_clusters' with the desired number of clusters\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m clustering \u001b[38;5;241m=\u001b[39m SpectralClustering(affinity\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m'\u001b[39m, n_clusters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mfit(\u001b[43mdf\u001b[49m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Add a new column to the dataframe with the cluster names\u001b[39;00m\n\u001b[1;32m     11\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster_name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m clustering\u001b[38;5;241m.\u001b[39mlabels_\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# append cluster to each row in your data source, example\n",
    "\n",
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "# Assuming 'df' is a pandas dataframe\n",
    "# Replace 'affinity' with the appropriate affinity matrix\n",
    "# Replace 'n_clusters' with the desired number of clusters\n",
    "clustering = SpectralClustering(affinity='...', n_clusters=..., random_state=0).fit(df)\n",
    "\n",
    "# Add a new column to the dataframe with the cluster names\n",
    "df['cluster_name'] = clustering.labels_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f432f579-c5e4-4cfb-b90d-5208ebd28da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## alternative: specifying cluster value\n",
    "import pandas as pd \n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, SpectralClustering \n",
    "from sklearn.metrics import silhouette_score \n",
    "\n",
    "# Load your dataset here \n",
    "data = ... \n",
    "# Define the clustering algorithms \n",
    "kmeans = KMeans(n_clusters=5) #\n",
    "hierarchical = AgglomerativeClustering(n_clusters=5) \n",
    "spectral = SpectralClustering(n_clusters=5) \n",
    "# Define the list of algorithms and their names \n",
    "algorithms = [(kmeans, 'KMeans'), (hierarchical, 'Agglomerative'), (spectral, 'Spectral')] \n",
    "# Define the list to store the silhouette scores \n",
    "scores = [] \n",
    "# Loop over the algorithms and calculate the silhouette score for each \n",
    "for algorithm, name in algorithms: \n",
    "# Fit the algorithm to the data \n",
    "algorithm.fit(data) \n",
    "    # Calculate the silhouette score \n",
    "score1 = silhouette_score(data, algorithm.labels_) \n",
    "# Calculate the Davies-Bouldin score \n",
    " score2 = davies_bouldin_score(data, algorithm.labels_) \n",
    "# Append the score to the list of scores \n",
    "scores.append(score) \n",
    "# Create a dataframe to store the results \n",
    "results = pd.DataFrame({'Algorithm': [name for _, name in algorithms], 'Silhouette Score': scores}) \n",
    "# Print the results \n",
    "print(results) \n",
    "#SPAGHETTI CHART: \n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd \n",
    "\n",
    "# Load the data \n",
    "data = pd.read_csv('events.csv') \n",
    "# Create a color palette \n",
    "palette = plt.get_cmap('Set1') \n",
    "# Plot the data \n",
    "for i, row in data.iterrows(): \n",
    "    plt.plot([row['time']], [row['price']], marker='o', color=palette(i % 9), alpha=0.5) \n",
    "    # Add labels and titles \n",
    "    plt.xlabel('Time') \n",
    "    plt.ylabel('Price') \n",
    "    plt.title('Spaghetti Plot of Event Prices') \n",
    "# Show the plot \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ec91dc-e6a0-4194-a7fe-e7c04cd31b42",
   "metadata": {},
   "source": [
    "## notes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed17c724-9a6c-4280-a565-b4a9f9904db8",
   "metadata": {},
   "source": [
    "1. grid search notes on [sklearn](https://scikit-learn.org/stable/modules/grid_search.html#grid-search)\n",
    "2. sklearn pipeline [guide](https://scikit-learn.org/stable/modules/compose.html#pipeline)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
